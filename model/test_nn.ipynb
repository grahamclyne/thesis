{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/xarray/conventions.py:521: SerializationWarning: variable 'cLeaf' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/xarray/conventions.py:521: SerializationWarning: variable 'gpp' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/xarray/conventions.py:521: SerializationWarning: variable 'rGrowth' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/xarray/conventions.py:521: SerializationWarning: variable 'cVeg' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n"
     ]
    }
   ],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "from draft_nn import Net, CMIPDataset\n",
    "import numpy as np\n",
    "ds = CMIPDataset([\n",
    "    'cLeaf_Lmon_CESM2_land-hist_r1i1p1f1_gn_185001-201512.nc',\n",
    "    'gpp_Lmon_CESM2_land-hist_r1i1p1f1_gn_185001-201512.nc',\n",
    "    'rGrowth_Lmon_CESM2_land-hist_r1i1p1f1_gn_185001-201512.nc',\n",
    "    'cVeg_Lmon_CESM2_land-hist_r1i1p1f1_gn_185001-201512.nc'],\n",
    "    '/Users/gclyne/thesis/data/NABoreal.shp','/Users/gclyne/thesis/data/'\n",
    "    )\n",
    "ds.data = (ds.data - ds.data.mean()) / ds.data.std() #where should this be done? \n",
    "\n",
    "ds = T.utils.data.Subset(ds, list(range(0,100)))\n",
    "train_set_size = int(len(ds) * 0.8)\n",
    "valid_set_size = len(ds) - train_set_size\n",
    "train,test = T.utils.data.random_split(ds, [train_set_size, valid_set_size], generator=T.Generator().manual_seed(42))\n",
    "\n",
    "model = Net()\n",
    "loss_function = nn.MSELoss()\n",
    "learning_rate = 0.05\n",
    "train_ldr = T.utils.data.DataLoader(train,batch_size=1,shuffle=True)\n",
    "test_ldr = T.utils.data.DataLoader(test,batch_size=1,shuffle=True)\n",
    "optimizer = T.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1466,  1.0493, -1.2175,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3090], grad_fn=<SelectBackward0>) tensor([0.3331], dtype=torch.float64)\n",
      "grad None\n",
      "0.0005815273034386337\n",
      "grad None\n",
      "tensor([[ 0.1470,  1.0493, -1.1679,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3114], grad_fn=<SelectBackward0>) tensor([0.3459], dtype=torch.float64)\n",
      "grad None\n",
      "0.001189477159641683\n",
      "grad None\n",
      "tensor([[ 0.1492,  1.1240, -1.5888,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3149], grad_fn=<SelectBackward0>) tensor([0.4095], dtype=torch.float64)\n",
      "grad None\n",
      "0.008953613229095936\n",
      "grad None\n",
      "tensor([[ 0.1479,  1.1240, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3243], grad_fn=<SelectBackward0>) tensor([0.3550], dtype=torch.float64)\n",
      "grad None\n",
      "0.000939429213758558\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.0866, -1.6631,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3274], grad_fn=<SelectBackward0>) tensor([0.2921], dtype=torch.float64)\n",
      "grad None\n",
      "0.001248720451258123\n",
      "grad None\n",
      "tensor([[ 0.1473,  1.0493, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3239], grad_fn=<SelectBackward0>) tensor([0.3515], dtype=torch.float64)\n",
      "grad None\n",
      "0.0007658876129426062\n",
      "grad None\n",
      "tensor([[ 0.1467,  1.0866, -1.5145,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3266], grad_fn=<SelectBackward0>) tensor([0.3230], dtype=torch.float64)\n",
      "grad None\n",
      "1.304985835304251e-05\n",
      "grad None\n",
      "tensor([[ 0.1454,  1.0493, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3263], grad_fn=<SelectBackward0>) tensor([0.3394], dtype=torch.float64)\n",
      "grad None\n",
      "0.00017261556058656424\n",
      "grad None\n",
      "tensor([[ 0.1459,  1.1053, -1.4403,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3276], grad_fn=<SelectBackward0>) tensor([0.2623], dtype=torch.float64)\n",
      "grad None\n",
      "0.004265980329364538\n",
      "grad None\n",
      "tensor([[ 0.1462,  1.1053, -1.4155,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3211], grad_fn=<SelectBackward0>) tensor([0.2762], dtype=torch.float64)\n",
      "grad None\n",
      "0.0020149261690676212\n",
      "grad None\n",
      "tensor([[ 0.1449,  1.0680, -1.6631,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3166], grad_fn=<SelectBackward0>) tensor([0.2661], dtype=torch.float64)\n",
      "grad None\n",
      "0.00255159311927855\n",
      "grad None\n",
      "tensor([[ 0.1450,  1.0680, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3115], grad_fn=<SelectBackward0>) tensor([0.2546], dtype=torch.float64)\n",
      "grad None\n",
      "0.0032400721684098244\n",
      "grad None\n",
      "tensor([[ 0.1470,  1.1053, -1.5640,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3058], grad_fn=<SelectBackward0>) tensor([0.2999], dtype=torch.float64)\n",
      "grad None\n",
      "3.557226955308579e-05\n",
      "grad None\n",
      "tensor([[ 0.1468,  1.0866, -1.3660,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3052], grad_fn=<SelectBackward0>) tensor([0.3106], dtype=torch.float64)\n",
      "grad None\n",
      "2.9129130780347623e-05\n",
      "grad None\n",
      "tensor([[ 0.1486,  1.0866, -1.2670,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3058], grad_fn=<SelectBackward0>) tensor([0.3818], dtype=torch.float64)\n",
      "grad None\n",
      "0.00577890919521451\n",
      "grad None\n",
      "tensor([[ 0.1469,  1.0493, -1.1927,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3134], grad_fn=<SelectBackward0>) tensor([0.3441], dtype=torch.float64)\n",
      "grad None\n",
      "0.0009448445634916425\n",
      "grad None\n",
      "tensor([[ 0.1490,  1.1053, -1.5393,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3164], grad_fn=<SelectBackward0>) tensor([0.4005], dtype=torch.float64)\n",
      "grad None\n",
      "0.00705924816429615\n",
      "grad None\n",
      "tensor([[ 0.1442,  1.1053, -1.7621,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3249], grad_fn=<SelectBackward0>) tensor([0.1623], dtype=torch.float64)\n",
      "grad None\n",
      "0.02642233856022358\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.1240, -1.6631,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3086], grad_fn=<SelectBackward0>) tensor([0.2611], dtype=torch.float64)\n",
      "grad None\n",
      "0.0022531352005898952\n",
      "grad None\n",
      "tensor([[ 0.1447,  1.0680, -1.7126,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3038], grad_fn=<SelectBackward0>) tensor([0.2890], dtype=torch.float64)\n",
      "grad None\n",
      "0.00022090387938078493\n",
      "grad None\n",
      "tensor([[ 0.1476,  1.0866, -0.9204,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3024], grad_fn=<SelectBackward0>) tensor([0.3215], dtype=torch.float64)\n",
      "grad None\n",
      "0.0003654698666650802\n",
      "grad None\n",
      "tensor([[ 0.1442,  1.0866, -1.5640,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3043], grad_fn=<SelectBackward0>) tensor([0.1476], dtype=torch.float64)\n",
      "grad None\n",
      "0.024561503902077675\n",
      "grad None\n",
      "tensor([[ 0.1470,  1.1053, -1.1927,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2886], grad_fn=<SelectBackward0>) tensor([0.3240], dtype=torch.float64)\n",
      "grad None\n",
      "0.0012519261799752712\n",
      "grad None\n",
      "tensor([[ 0.1464,  1.0866, -1.4650,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2921], grad_fn=<SelectBackward0>) tensor([0.2869], dtype=torch.float64)\n",
      "grad None\n",
      "2.7617674277280457e-05\n",
      "grad None\n",
      "tensor([[ 0.1450,  1.0680, -1.6878,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2916], grad_fn=<SelectBackward0>) tensor([0.3181], dtype=torch.float64)\n",
      "grad None\n",
      "0.0006995225558057427\n",
      "grad None\n",
      "tensor([[ 0.1466,  1.0680, -1.2175,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2943], grad_fn=<SelectBackward0>) tensor([0.3366], dtype=torch.float64)\n",
      "grad None\n",
      "0.0017964892322197556\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.1053, -1.2670,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2985], grad_fn=<SelectBackward0>) tensor([0.2661], dtype=torch.float64)\n",
      "grad None\n",
      "0.0010505971731618047\n",
      "grad None\n",
      "tensor([[ 0.1443,  1.1240, -1.8116,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2953], grad_fn=<SelectBackward0>) tensor([0.1792], dtype=torch.float64)\n",
      "grad None\n",
      "0.01347780879586935\n",
      "grad None\n",
      "tensor([[ 0.1458,  1.0493, -1.6135,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2836], grad_fn=<SelectBackward0>) tensor([0.3412], dtype=torch.float64)\n",
      "grad None\n",
      "0.0033080466091632843\n",
      "grad None\n",
      "tensor([[ 0.1445,  1.0866, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2894], grad_fn=<SelectBackward0>) tensor([0.1699], dtype=torch.float64)\n",
      "grad None\n",
      "0.014287016354501247\n",
      "grad None\n",
      "tensor([[ 0.1472,  1.1240, -1.5145,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2774], grad_fn=<SelectBackward0>) tensor([0.3196], dtype=torch.float64)\n",
      "grad None\n",
      "0.0017737939488142729\n",
      "grad None\n",
      "tensor([[ 0.1465,  1.1053, -1.3907,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2817], grad_fn=<SelectBackward0>) tensor([0.2890], dtype=torch.float64)\n",
      "grad None\n",
      "5.3491930884774774e-05\n",
      "grad None\n",
      "tensor([[ 0.1473,  1.0493, -1.0689,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2824], grad_fn=<SelectBackward0>) tensor([0.3221], dtype=torch.float64)\n",
      "grad None\n",
      "0.0015750443562865257\n",
      "grad None\n",
      "tensor([[ 0.1471,  1.0866, -1.2917,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2864], grad_fn=<SelectBackward0>) tensor([0.3258], dtype=torch.float64)\n",
      "grad None\n",
      "0.001555142691358924\n",
      "grad None\n",
      "tensor([[ 0.1447,  1.1053, -1.5888,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2903], grad_fn=<SelectBackward0>) tensor([0.1782], dtype=torch.float64)\n",
      "grad None\n",
      "0.012566347606480122\n",
      "grad None\n",
      "tensor([[ 0.1467,  1.1053, -1.3660,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2791], grad_fn=<SelectBackward0>) tensor([0.2845], dtype=torch.float64)\n",
      "grad None\n",
      "2.919962389569264e-05\n",
      "grad None\n",
      "tensor([[ 0.1480,  1.0306, -1.1927,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2796], grad_fn=<SelectBackward0>) tensor([0.3748], dtype=torch.float64)\n",
      "grad None\n",
      "0.00904875248670578\n",
      "grad None\n",
      "tensor([[ 0.1455,  1.1053, -1.7373,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2891], grad_fn=<SelectBackward0>) tensor([0.2698], dtype=torch.float64)\n",
      "grad None\n",
      "0.0003729669260792434\n",
      "grad None\n",
      "tensor([[ 0.1467,  1.1053, -0.9699,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2872], grad_fn=<SelectBackward0>) tensor([0.2856], dtype=torch.float64)\n",
      "grad None\n",
      "2.722026692936197e-06\n",
      "grad None\n",
      "tensor([[ 0.1454,  1.0866, -1.5393,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2870], grad_fn=<SelectBackward0>) tensor([0.2315], dtype=torch.float64)\n",
      "grad None\n",
      "0.0030866479501128197\n",
      "grad None\n",
      "tensor([[ 0.1458,  1.1053, -1.4898,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2815], grad_fn=<SelectBackward0>) tensor([0.2563], dtype=torch.float64)\n",
      "grad None\n",
      "0.0006324686110019684\n",
      "grad None\n",
      "tensor([[ 0.1477,  1.0680, -1.1679,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2790], grad_fn=<SelectBackward0>) tensor([0.3698], dtype=torch.float64)\n",
      "grad None\n",
      "0.008257555775344372\n",
      "grad None\n",
      "tensor([[ 0.1464,  1.0866, -1.4898,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2881], grad_fn=<SelectBackward0>) tensor([0.2911], dtype=torch.float64)\n",
      "grad None\n",
      "9.126091754296795e-06\n",
      "grad None\n",
      "tensor([[ 0.1470,  1.1053, -1.3412,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2884], grad_fn=<SelectBackward0>) tensor([0.2862], dtype=torch.float64)\n",
      "grad None\n",
      "4.705264018411981e-06\n",
      "grad None\n",
      "tensor([[ 0.1471,  1.1240, -1.6135,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2882], grad_fn=<SelectBackward0>) tensor([0.3107], dtype=torch.float64)\n",
      "grad None\n",
      "0.00050630938494578\n",
      "grad None\n",
      "tensor([[ 0.1472,  1.1053, -1.5145,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2904], grad_fn=<SelectBackward0>) tensor([0.3183], dtype=torch.float64)\n",
      "grad None\n",
      "0.0007758899009786546\n",
      "grad None\n",
      "tensor([[ 0.1464,  1.1053, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2932], grad_fn=<SelectBackward0>) tensor([0.2982], dtype=torch.float64)\n",
      "grad None\n",
      "2.4757060600677505e-05\n",
      "grad None\n",
      "tensor([[ 0.1476,  1.0680, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2937], grad_fn=<SelectBackward0>) tensor([0.3549], dtype=torch.float64)\n",
      "grad None\n",
      "0.0037417702842503786\n",
      "grad None\n",
      "tensor([[ 0.1441,  1.1240, -1.8859,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2998], grad_fn=<SelectBackward0>) tensor([0.1613], dtype=torch.float64)\n",
      "grad None\n",
      "0.01918787695467472\n",
      "grad None\n",
      "tensor([[ 0.1441,  1.1240, -1.8611,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2859], grad_fn=<SelectBackward0>) tensor([0.1476], dtype=torch.float64)\n",
      "grad None\n",
      "0.019142938777804375\n",
      "grad None\n",
      "tensor([[ 0.1486,  1.1053, -1.1679,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2721], grad_fn=<SelectBackward0>) tensor([0.3946], dtype=torch.float64)\n",
      "grad None\n",
      "0.015012654475867748\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.1053, -1.4650,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2844], grad_fn=<SelectBackward0>) tensor([0.2692], dtype=torch.float64)\n",
      "grad None\n",
      "0.0002308829571120441\n",
      "grad None\n",
      "tensor([[ 0.1459,  1.1053, -1.6878,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2828], grad_fn=<SelectBackward0>) tensor([0.2895], dtype=torch.float64)\n",
      "grad None\n",
      "4.487215483095497e-05\n",
      "grad None\n",
      "tensor([[ 0.1453,  1.0680, -1.6135,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2835], grad_fn=<SelectBackward0>) tensor([0.3114], dtype=torch.float64)\n",
      "grad None\n",
      "0.0007773416582494974\n",
      "grad None\n",
      "tensor([[ 0.1448,  1.0866, -1.7373,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2863], grad_fn=<SelectBackward0>) tensor([0.2745], dtype=torch.float64)\n",
      "grad None\n",
      "0.00013926159590482712\n",
      "grad None\n",
      "tensor([[ 0.1468,  1.0866, -1.4155,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2851], grad_fn=<SelectBackward0>) tensor([0.3076], dtype=torch.float64)\n",
      "grad None\n",
      "0.000503470073454082\n",
      "grad None\n",
      "tensor([[ 0.1475,  1.1053, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2874], grad_fn=<SelectBackward0>) tensor([0.3518], dtype=torch.float64)\n",
      "grad None\n",
      "0.004149972926825285\n",
      "grad None\n",
      "tensor([[ 0.1453,  1.0680, -1.5393,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2938], grad_fn=<SelectBackward0>) tensor([0.2460], dtype=torch.float64)\n",
      "grad None\n",
      "0.0022899103350937366\n",
      "grad None\n",
      "tensor([[ 0.1461,  1.1053, -1.6631,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2890], grad_fn=<SelectBackward0>) tensor([0.2822], dtype=torch.float64)\n",
      "grad None\n",
      "4.712119698524475e-05\n",
      "grad None\n",
      "tensor([[ 0.1465,  1.1053, -0.9451,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2883], grad_fn=<SelectBackward0>) tensor([0.2704], dtype=torch.float64)\n",
      "grad None\n",
      "0.0003213289310224354\n",
      "grad None\n",
      "tensor([[ 0.1465,  1.0866, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2865], grad_fn=<SelectBackward0>) tensor([0.3114], dtype=torch.float64)\n",
      "grad None\n",
      "0.0006199307972565293\n",
      "grad None\n",
      "tensor([[ 0.1483,  1.1240, -1.5640,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2890], grad_fn=<SelectBackward0>) tensor([0.3682], dtype=torch.float64)\n",
      "grad None\n",
      "0.006270491983741522\n",
      "grad None\n",
      "tensor([[ 0.1455,  1.0306, -1.2670,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2970], grad_fn=<SelectBackward0>) tensor([0.3245], dtype=torch.float64)\n",
      "grad None\n",
      "0.0007605770952068269\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.0866, -1.6878,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2997], grad_fn=<SelectBackward0>) tensor([0.3436], dtype=torch.float64)\n",
      "grad None\n",
      "0.0019262745045125484\n",
      "grad None\n",
      "tensor([[ 0.1451,  1.0680, -1.5888,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3041], grad_fn=<SelectBackward0>) tensor([0.2349], dtype=torch.float64)\n",
      "grad None\n",
      "0.00478903716430068\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.1053, -1.7126,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2972], grad_fn=<SelectBackward0>) tensor([0.2981], dtype=torch.float64)\n",
      "grad None\n",
      "9.33583180540154e-07\n",
      "grad None\n",
      "tensor([[ 0.1455,  1.1240, -1.7621,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2973], grad_fn=<SelectBackward0>) tensor([0.2602], dtype=torch.float64)\n",
      "grad None\n",
      "0.0013729482889175415\n",
      "grad None\n",
      "tensor([[ 0.1465,  1.0680, -1.4650,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2936], grad_fn=<SelectBackward0>) tensor([0.3061], dtype=torch.float64)\n",
      "grad None\n",
      "0.0001557799259899184\n",
      "grad None\n",
      "tensor([[ 0.1457,  1.0866, -1.7126,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2948], grad_fn=<SelectBackward0>) tensor([0.3155], dtype=torch.float64)\n",
      "grad None\n",
      "0.0004285199393052608\n",
      "grad None\n",
      "tensor([[ 0.1469,  1.0866, -1.3165,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2969], grad_fn=<SelectBackward0>) tensor([0.3037], dtype=torch.float64)\n",
      "grad None\n",
      "4.643672946258448e-05\n",
      "grad None\n",
      "tensor([[ 0.1482,  1.1053, -1.2422,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2976], grad_fn=<SelectBackward0>) tensor([0.3609], dtype=torch.float64)\n",
      "grad None\n",
      "0.004014452453702688\n",
      "grad None\n",
      "tensor([[ 0.1443,  1.0866, -1.6135,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3039], grad_fn=<SelectBackward0>) tensor([0.1601], dtype=torch.float64)\n",
      "grad None\n",
      "0.020681004971265793\n",
      "grad None\n",
      "tensor([[ 0.1463,  1.0493, -1.2422,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2895], grad_fn=<SelectBackward0>) tensor([0.3440], dtype=torch.float64)\n",
      "grad None\n",
      "0.0029651664663106203\n",
      "grad None\n",
      "tensor([[ 0.1449,  1.0680, -1.7373,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2950], grad_fn=<SelectBackward0>) tensor([0.2871], dtype=torch.float64)\n",
      "grad None\n",
      "6.165418744785711e-05\n",
      "grad None\n",
      "tensor([[ 0.1469,  1.1053, -0.9947,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2942], grad_fn=<SelectBackward0>) tensor([0.2920], dtype=torch.float64)\n",
      "grad None\n",
      "4.72079182145535e-06\n",
      "grad None\n",
      "tensor([[ 0.1473,  1.1240, -1.5393,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2940], grad_fn=<SelectBackward0>) tensor([0.3143], dtype=torch.float64)\n",
      "grad None\n",
      "0.0004118940560147166\n",
      "grad None\n",
      "tensor([[ 0.1468,  1.0866, -1.3907,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2960], grad_fn=<SelectBackward0>) tensor([0.3081], dtype=torch.float64)\n",
      "grad None\n",
      "0.00014682020992040634\n",
      "grad None\n",
      "tensor([[ 0.1479,  1.0306, -1.1184,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2972], grad_fn=<SelectBackward0>) tensor([0.3555], dtype=torch.float64)\n",
      "grad None\n",
      "0.003396863117814064\n",
      "grad None\n",
      "tensor([[ 0.1462,  1.0866, -1.4403,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3030], grad_fn=<SelectBackward0>) tensor([0.2790], dtype=torch.float64)\n",
      "grad None\n",
      "0.0005796013865619898\n",
      "grad None\n",
      "tensor([[ 0.1478,  1.0306, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3006], grad_fn=<SelectBackward0>) tensor([0.3615], dtype=torch.float64)\n",
      "grad None\n",
      "0.003701608395203948\n",
      "grad None\n",
      "Epoch 1 \t\t Training Loss: 0.28770601148841024 \t\t Validation Loss: 0.07223869389395077\n",
      "Validation Loss Decreased(inf--->0.072239)\n",
      "tensor([[ 0.1473,  1.0493, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3067], grad_fn=<SelectBackward0>) tensor([0.3515], dtype=torch.float64)\n",
      "grad None\n",
      "0.0020100169349461794\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.1053, -1.7126,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3112], grad_fn=<SelectBackward0>) tensor([0.2981], dtype=torch.float64)\n",
      "grad None\n",
      "0.00017035435303114355\n",
      "grad None\n",
      "tensor([[ 0.1457,  1.0866, -1.7126,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3099], grad_fn=<SelectBackward0>) tensor([0.3155], dtype=torch.float64)\n",
      "grad None\n",
      "3.166454189340584e-05\n",
      "grad None\n",
      "tensor([[ 0.1461,  1.1053, -1.6631,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3105], grad_fn=<SelectBackward0>) tensor([0.2822], dtype=torch.float64)\n",
      "grad None\n",
      "0.0008006750722415745\n",
      "grad None\n",
      "tensor([[ 0.1451,  1.0680, -1.5888,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3076], grad_fn=<SelectBackward0>) tensor([0.2349], dtype=torch.float64)\n",
      "grad None\n",
      "0.005289462860673666\n",
      "grad None\n",
      "tensor([[ 0.1464,  1.0866, -1.4898,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3004], grad_fn=<SelectBackward0>) tensor([0.2911], dtype=torch.float64)\n",
      "grad None\n",
      "8.588451601099223e-05\n",
      "grad None\n",
      "tensor([[ 0.1454,  1.0866, -1.5393,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2994], grad_fn=<SelectBackward0>) tensor([0.2315], dtype=torch.float64)\n",
      "grad None\n",
      "0.00461525609716773\n",
      "grad None\n",
      "tensor([[ 0.1469,  1.1053, -0.9947,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2926], grad_fn=<SelectBackward0>) tensor([0.2920], dtype=torch.float64)\n",
      "grad None\n",
      "3.838551947410451e-07\n",
      "grad None\n",
      "tensor([[ 0.1447,  1.1053, -1.5888,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2926], grad_fn=<SelectBackward0>) tensor([0.1782], dtype=torch.float64)\n",
      "grad None\n",
      "0.01308025885373354\n",
      "grad None\n",
      "tensor([[ 0.1459,  1.1053, -1.6878,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2811], grad_fn=<SelectBackward0>) tensor([0.2895], dtype=torch.float64)\n",
      "grad None\n",
      "7.07307190168649e-05\n",
      "grad None\n",
      "tensor([[ 0.1454,  1.0493, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2820], grad_fn=<SelectBackward0>) tensor([0.3394], dtype=torch.float64)\n",
      "grad None\n",
      "0.0032996870577335358\n",
      "grad None\n",
      "tensor([[ 0.1455,  1.0306, -1.2670,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2877], grad_fn=<SelectBackward0>) tensor([0.3245], dtype=torch.float64)\n",
      "grad None\n",
      "0.0013551743468269706\n",
      "grad None\n",
      "tensor([[ 0.1466,  1.0493, -1.2175,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2914], grad_fn=<SelectBackward0>) tensor([0.3331], dtype=torch.float64)\n",
      "grad None\n",
      "0.0017416977789252996\n",
      "grad None\n",
      "tensor([[ 0.1445,  1.0866, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2956], grad_fn=<SelectBackward0>) tensor([0.1699], dtype=torch.float64)\n",
      "grad None\n",
      "0.015801241621375084\n",
      "grad None\n",
      "tensor([[ 0.1455,  1.1053, -1.7373,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2830], grad_fn=<SelectBackward0>) tensor([0.2698], dtype=torch.float64)\n",
      "grad None\n",
      "0.00017348668188787997\n",
      "grad None\n",
      "tensor([[ 0.1473,  1.0493, -1.0689,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2817], grad_fn=<SelectBackward0>) tensor([0.3221], dtype=torch.float64)\n",
      "grad None\n",
      "0.0016313340747728944\n",
      "grad None\n",
      "tensor([[ 0.1467,  1.1053, -0.9699,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2857], grad_fn=<SelectBackward0>) tensor([0.2856], dtype=torch.float64)\n",
      "grad None\n",
      "2.6245757567266992e-08\n",
      "grad None\n",
      "tensor([[ 0.1443,  1.1240, -1.8116,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2857], grad_fn=<SelectBackward0>) tensor([0.1792], dtype=torch.float64)\n",
      "grad None\n",
      "0.01135207898914814\n",
      "grad None\n",
      "tensor([[ 0.1468,  1.0866, -1.3907,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2751], grad_fn=<SelectBackward0>) tensor([0.3081], dtype=torch.float64)\n",
      "grad None\n",
      "0.0010930000571534038\n",
      "grad None\n",
      "tensor([[ 0.1449,  1.0680, -1.6631,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2784], grad_fn=<SelectBackward0>) tensor([0.2661], dtype=torch.float64)\n",
      "grad None\n",
      "0.00015131014515645802\n",
      "grad None\n",
      "tensor([[ 0.1472,  1.1240, -1.5145,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2771], grad_fn=<SelectBackward0>) tensor([0.3196], dtype=torch.float64)\n",
      "grad None\n",
      "0.0018004956655204296\n",
      "grad None\n",
      "tensor([[ 0.1473,  1.1240, -1.5393,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2814], grad_fn=<SelectBackward0>) tensor([0.3143], dtype=torch.float64)\n",
      "grad None\n",
      "0.0010817574802786112\n",
      "grad None\n",
      "tensor([[ 0.1468,  1.0866, -1.3660,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2847], grad_fn=<SelectBackward0>) tensor([0.3106], dtype=torch.float64)\n",
      "grad None\n",
      "0.0006743130506947637\n",
      "grad None\n",
      "tensor([[ 0.1455,  1.1240, -1.7621,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2873], grad_fn=<SelectBackward0>) tensor([0.2602], dtype=torch.float64)\n",
      "grad None\n",
      "0.0007309668581001461\n",
      "grad None\n",
      "tensor([[ 0.1462,  1.0866, -1.4403,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2846], grad_fn=<SelectBackward0>) tensor([0.2790], dtype=torch.float64)\n",
      "grad None\n",
      "3.127800300717354e-05\n",
      "grad None\n",
      "tensor([[ 0.1490,  1.1053, -1.5393,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2840], grad_fn=<SelectBackward0>) tensor([0.4005], dtype=torch.float64)\n",
      "grad None\n",
      "0.013565575703978539\n",
      "grad None\n",
      "tensor([[ 0.1441,  1.1240, -1.8859,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2956], grad_fn=<SelectBackward0>) tensor([0.1613], dtype=torch.float64)\n",
      "grad None\n",
      "0.018053682520985603\n",
      "grad None\n",
      "tensor([[ 0.1443,  1.0866, -1.6135,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2822], grad_fn=<SelectBackward0>) tensor([0.1601], dtype=torch.float64)\n",
      "grad None\n",
      "0.014910741709172726\n",
      "grad None\n",
      "tensor([[ 0.1476,  1.0680, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2700], grad_fn=<SelectBackward0>) tensor([0.3549], dtype=torch.float64)\n",
      "grad None\n",
      "0.007200662512332201\n",
      "grad None\n",
      "tensor([[ 0.1442,  1.0866, -1.5640,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2785], grad_fn=<SelectBackward0>) tensor([0.1476], dtype=torch.float64)\n",
      "grad None\n",
      "0.01714234985411167\n",
      "grad None\n",
      "tensor([[ 0.1453,  1.0680, -1.6135,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2654], grad_fn=<SelectBackward0>) tensor([0.3114], dtype=torch.float64)\n",
      "grad None\n",
      "0.0021166366059333086\n",
      "grad None\n",
      "tensor([[ 0.1470,  1.1053, -1.3412,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2700], grad_fn=<SelectBackward0>) tensor([0.2862], dtype=torch.float64)\n",
      "grad None\n",
      "0.00026269227964803576\n",
      "grad None\n",
      "tensor([[ 0.1468,  1.0866, -1.4155,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2716], grad_fn=<SelectBackward0>) tensor([0.3076], dtype=torch.float64)\n",
      "grad None\n",
      "0.0012924564070999622\n",
      "grad None\n",
      "tensor([[ 0.1475,  1.1053, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2752], grad_fn=<SelectBackward0>) tensor([0.3518], dtype=torch.float64)\n",
      "grad None\n",
      "0.00586474547162652\n",
      "grad None\n",
      "tensor([[ 0.1448,  1.0866, -1.7373,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2829], grad_fn=<SelectBackward0>) tensor([0.2745], dtype=torch.float64)\n",
      "grad None\n",
      "6.99139927746728e-05\n",
      "grad None\n",
      "tensor([[ 0.1486,  1.0866, -1.2670,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2820], grad_fn=<SelectBackward0>) tensor([0.3818], dtype=torch.float64)\n",
      "grad None\n",
      "0.00995290745049715\n",
      "grad None\n",
      "tensor([[ 0.1479,  1.0306, -1.1184,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2920], grad_fn=<SelectBackward0>) tensor([0.3555], dtype=torch.float64)\n",
      "grad None\n",
      "0.004030765034258366\n",
      "grad None\n",
      "tensor([[ 0.1470,  1.1053, -1.5640,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2984], grad_fn=<SelectBackward0>) tensor([0.2999], dtype=torch.float64)\n",
      "grad None\n",
      "2.287198412886937e-06\n",
      "grad None\n",
      "tensor([[ 0.1449,  1.0680, -1.7373,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2985], grad_fn=<SelectBackward0>) tensor([0.2871], dtype=torch.float64)\n",
      "grad None\n",
      "0.00012962079199496657\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.1240, -1.6631,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2974], grad_fn=<SelectBackward0>) tensor([0.2611], dtype=torch.float64)\n",
      "grad None\n",
      "0.0013131439918652177\n",
      "grad None\n",
      "tensor([[ 0.1470,  1.1053, -1.1927,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2937], grad_fn=<SelectBackward0>) tensor([0.3240], dtype=torch.float64)\n",
      "grad None\n",
      "0.0009146269876509905\n",
      "grad None\n",
      "tensor([[ 0.1480,  1.0306, -1.1927,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2968], grad_fn=<SelectBackward0>) tensor([0.3748], dtype=torch.float64)\n",
      "grad None\n",
      "0.006082537118345499\n",
      "grad None\n",
      "tensor([[ 0.1442,  1.1053, -1.7621,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3046], grad_fn=<SelectBackward0>) tensor([0.1623], dtype=torch.float64)\n",
      "grad None\n",
      "0.020239124074578285\n",
      "grad None\n",
      "tensor([[ 0.1486,  1.1053, -1.1679,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2903], grad_fn=<SelectBackward0>) tensor([0.3946], dtype=torch.float64)\n",
      "grad None\n",
      "0.010878382250666618\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.0866, -1.6631,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3008], grad_fn=<SelectBackward0>) tensor([0.2921], dtype=torch.float64)\n",
      "grad None\n",
      "7.567467400804162e-05\n",
      "grad None\n",
      "tensor([[ 0.1450,  1.0680, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2999], grad_fn=<SelectBackward0>) tensor([0.2546], dtype=torch.float64)\n",
      "grad None\n",
      "0.0020519853569567204\n",
      "grad None\n",
      "tensor([[ 0.1470,  1.0493, -1.1679,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2954], grad_fn=<SelectBackward0>) tensor([0.3459], dtype=torch.float64)\n",
      "grad None\n",
      "0.0025553491432219744\n",
      "grad None\n",
      "tensor([[ 0.1471,  1.0866, -1.2917,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3004], grad_fn=<SelectBackward0>) tensor([0.3258], dtype=torch.float64)\n",
      "grad None\n",
      "0.0006435976829379797\n",
      "grad None\n",
      "tensor([[ 0.1492,  1.1240, -1.5888,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3030], grad_fn=<SelectBackward0>) tensor([0.4095], dtype=torch.float64)\n",
      "grad None\n",
      "0.011351221241056919\n",
      "grad None\n",
      "tensor([[ 0.1458,  1.1053, -1.4898,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3136], grad_fn=<SelectBackward0>) tensor([0.2563], dtype=torch.float64)\n",
      "grad None\n",
      "0.003280042903497815\n",
      "grad None\n",
      "tensor([[ 0.1465,  1.0866, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3079], grad_fn=<SelectBackward0>) tensor([0.3114], dtype=torch.float64)\n",
      "grad None\n",
      "1.2639295164262876e-05\n",
      "grad None\n",
      "tensor([[ 0.1453,  1.0680, -1.5393,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3082], grad_fn=<SelectBackward0>) tensor([0.2460], dtype=torch.float64)\n",
      "grad None\n",
      "0.0038797282613813877\n",
      "grad None\n",
      "tensor([[ 0.1464,  1.0866, -1.4650,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3020], grad_fn=<SelectBackward0>) tensor([0.2869], dtype=torch.float64)\n",
      "grad None\n",
      "0.0002289046678924933\n",
      "grad None\n",
      "tensor([[ 0.1466,  1.0680, -1.2175,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3005], grad_fn=<SelectBackward0>) tensor([0.3366], dtype=torch.float64)\n",
      "grad None\n",
      "0.0013063125079497695\n",
      "grad None\n",
      "tensor([[ 0.1465,  1.0680, -1.4650,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3041], grad_fn=<SelectBackward0>) tensor([0.3061], dtype=torch.float64)\n",
      "grad None\n",
      "3.7486290693777846e-06\n",
      "grad None\n",
      "tensor([[ 0.1467,  1.1053, -1.3660,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3043], grad_fn=<SelectBackward0>) tensor([0.2845], dtype=torch.float64)\n",
      "grad None\n",
      "0.00039261524216271937\n",
      "grad None\n",
      "tensor([[ 0.1447,  1.0680, -1.7126,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3023], grad_fn=<SelectBackward0>) tensor([0.2890], dtype=torch.float64)\n",
      "grad None\n",
      "0.0001780159363988787\n",
      "grad None\n",
      "tensor([[ 0.1471,  1.1240, -1.6135,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3010], grad_fn=<SelectBackward0>) tensor([0.3107], dtype=torch.float64)\n",
      "grad None\n",
      "9.326043800683692e-05\n",
      "grad None\n",
      "tensor([[ 0.1479,  1.1240, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3020], grad_fn=<SelectBackward0>) tensor([0.3550], dtype=torch.float64)\n",
      "grad None\n",
      "0.0028124195523560047\n",
      "grad None\n",
      "tensor([[ 0.1458,  1.0493, -1.6135,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3073], grad_fn=<SelectBackward0>) tensor([0.3412], dtype=torch.float64)\n",
      "grad None\n",
      "0.0011492216726765037\n",
      "grad None\n",
      "tensor([[ 0.1482,  1.1053, -1.2422,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3107], grad_fn=<SelectBackward0>) tensor([0.3609], dtype=torch.float64)\n",
      "grad None\n",
      "0.002527815056964755\n",
      "grad None\n",
      "tensor([[ 0.1465,  1.1053, -0.9451,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3157], grad_fn=<SelectBackward0>) tensor([0.2704], dtype=torch.float64)\n",
      "grad None\n",
      "0.002049288945272565\n",
      "grad None\n",
      "tensor([[ 0.1472,  1.1053, -1.5145,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3112], grad_fn=<SelectBackward0>) tensor([0.3183], dtype=torch.float64)\n",
      "grad None\n",
      "5.0423768698237836e-05\n",
      "grad None\n",
      "tensor([[ 0.1476,  1.0866, -0.9204,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3119], grad_fn=<SelectBackward0>) tensor([0.3215], dtype=torch.float64)\n",
      "grad None\n",
      "9.24654959817417e-05\n",
      "grad None\n",
      "tensor([[ 0.1477,  1.0680, -1.1679,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3128], grad_fn=<SelectBackward0>) tensor([0.3698], dtype=torch.float64)\n",
      "grad None\n",
      "0.003251634771004319\n",
      "grad None\n",
      "tensor([[ 0.1478,  1.0306, -1.1432,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3185], grad_fn=<SelectBackward0>) tensor([0.3615], dtype=torch.float64)\n",
      "grad None\n",
      "0.0018441498978063464\n",
      "grad None\n",
      "tensor([[ 0.1464,  1.1053, -1.6383,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3228], grad_fn=<SelectBackward0>) tensor([0.2982], dtype=torch.float64)\n",
      "grad None\n",
      "0.0006081695319153368\n",
      "grad None\n",
      "tensor([[ 0.1459,  1.1053, -1.4403,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3204], grad_fn=<SelectBackward0>) tensor([0.2623], dtype=torch.float64)\n",
      "grad None\n",
      "0.0033729735296219587\n",
      "grad None\n",
      "tensor([[ 0.1450,  1.0680, -1.6878,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3145], grad_fn=<SelectBackward0>) tensor([0.3181], dtype=torch.float64)\n",
      "grad None\n",
      "1.2355260878393892e-05\n",
      "grad None\n",
      "tensor([[ 0.1467,  1.0866, -1.5145,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3149], grad_fn=<SelectBackward0>) tensor([0.3230], dtype=torch.float64)\n",
      "grad None\n",
      "6.606999522773549e-05\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.1053, -1.2670,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3157], grad_fn=<SelectBackward0>) tensor([0.2661], dtype=torch.float64)\n",
      "grad None\n",
      "0.0024628753308206797\n",
      "grad None\n",
      "tensor([[ 0.1463,  1.0493, -1.2422,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3108], grad_fn=<SelectBackward0>) tensor([0.3440], dtype=torch.float64)\n",
      "grad None\n",
      "0.0011041759280487895\n",
      "grad None\n",
      "tensor([[ 0.1469,  1.0866, -1.3165,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3141], grad_fn=<SelectBackward0>) tensor([0.3037], dtype=torch.float64)\n",
      "grad None\n",
      "0.00010751992522273213\n",
      "grad None\n",
      "tensor([[ 0.1483,  1.1240, -1.5640,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3130], grad_fn=<SelectBackward0>) tensor([0.3682], dtype=torch.float64)\n",
      "grad None\n",
      "0.003045392921194434\n",
      "grad None\n",
      "tensor([[ 0.1462,  1.1053, -1.4155,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3186], grad_fn=<SelectBackward0>) tensor([0.2762], dtype=torch.float64)\n",
      "grad None\n",
      "0.0017961128614842892\n",
      "grad None\n",
      "tensor([[ 0.1469,  1.0493, -1.1927,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3143], grad_fn=<SelectBackward0>) tensor([0.3441], dtype=torch.float64)\n",
      "grad None\n",
      "0.0008878409280441701\n",
      "grad None\n",
      "tensor([[ 0.1441,  1.1240, -1.8611,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3173], grad_fn=<SelectBackward0>) tensor([0.1476], dtype=torch.float64)\n",
      "grad None\n",
      "0.028800157830119133\n",
      "grad None\n",
      "tensor([[ 0.1465,  1.1053, -1.3907,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.3003], grad_fn=<SelectBackward0>) tensor([0.2890], dtype=torch.float64)\n",
      "grad None\n",
      "0.00012890720972791314\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.1053, -1.4650,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2992], grad_fn=<SelectBackward0>) tensor([0.2692], dtype=torch.float64)\n",
      "grad None\n",
      "0.0009012074442580342\n",
      "grad None\n",
      "tensor([[ 0.1460,  1.0866, -1.6878,  0.1441,  0.1441]], dtype=torch.float64) tensor([0.2962], grad_fn=<SelectBackward0>) tensor([0.3436], dtype=torch.float64)\n",
      "grad None\n",
      "0.0022479351609945297\n",
      "grad None\n",
      "Epoch 2 \t\t Training Loss: 0.2864675968142052 \t\t Validation Loss: 0.07119053421956778\n",
      "Validation Loss Decreased(0.072239--->0.071191)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "min_valid_loss = np.inf\n",
    "for epoch in range(2):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for X,y in train_ldr:\n",
    "        pred_y = model(X.float())[0]\n",
    "\n",
    "        print(X,pred_y,y)\n",
    "        loss = loss_function(pred_y, y.float())\n",
    "        optimizer.zero_grad() #clears old gradients from previous steps \n",
    "        loss.backward() #compute gradient\n",
    "        optimizer.step() #take step based on gradient\n",
    "        train_loss += loss.item()\n",
    "        print(loss.item())\n",
    "\n",
    "    losses.append(train_loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    for X,y in test_ldr:\n",
    "        pred_y = model(X.float())\n",
    "        test_loss = loss_function(pred_y,y.float())\n",
    "        valid_loss += test_loss.item() * X.size(0)\n",
    "\n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {train_loss} \\t\\t Validation Loss: {valid_loss}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f})')\n",
    "        min_valid_loss = valid_loss\n",
    "plt.plot(losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title(\"Learning rate %f\"%(learning_rate))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e0c4f7d72d6763faf0104f2098797ce8b3918906d1e9314e43a03dbc110a505"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('3.9.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
