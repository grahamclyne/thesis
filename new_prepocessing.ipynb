{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "\n",
    "regrowth = rioxarray.open_rasterio(f'/Users/gclyne/Downloads/CA_forest_harvest_years2recovery/CA_forest_harvest_years2recovery.tif',decode_coords='all',lock=False,chunks=True).sel(band=1)\n",
    "# regrowth.rio.reproject('EPSG:4326').rio.to_raster(f'/Users/gclyne/Downloads/CA_forest_harvest_years2recovery/CA_forest_harvest_years2recovery_reprojected.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrowth.rio.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrowth_sub = regrowth.sel(x=slice(-2660895.524,-2560895.524),y=slice(2998833.1105,2898833.1105))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(x.data,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ecozones_coords = pd.read_csv('/Users/gclyne/thesis/data/ecozones_coordinates.csv')\n",
    "from preprocessing.utils import getGeometryBoxes\n",
    "\n",
    "boxes = getGeometryBoxes(ecozones_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "wgs84 = pyproj.CRS('EPSG:4326')\n",
    "utm = pyproj.CRS('EPSG:3978')\n",
    "\n",
    "project = pyproj.Transformer.from_crs(wgs84, utm, always_xy=True).transform\n",
    "transformed_box = transform(project, boxes[0])\n",
    "bbox = transformed_box.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = regrowth.sel(x=slice(bbox[0],bbox[2]),y=slice(bbox[3],bbox[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], dtype=int8),\n",
       " array([17816419,      959,      820,      480,      348,      222,\n",
       "             206,      180,      171,      100,       69,       64,\n",
       "              50,       29,       48,       44,       29,       30,\n",
       "              48,       37,       23,       31,       21,       23,\n",
       "              24,        7,       10,        4,        3,        7,\n",
       "               4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(s,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.536617647091835e-05"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "452/17819004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3826753849917876e-05"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "959/17816419    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7053673871764385e-05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "228/6153236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rio.to_raster('sel_raster.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometries = [\n",
    "    {\n",
    "        'type': 'Polygon',\n",
    "        'coordinates': [[\n",
    "            [425499.18381405267, 4615331.540546387],\n",
    "            [425499.18381405267, 4615478.540546387],\n",
    "            [425526.18381405267, 4615478.540546387],\n",
    "            [425526.18381405267, 4615331.540546387],\n",
    "            [425499.18381405267, 4615331.540546387]\n",
    "        ]]\n",
    "    }\n",
    "]    \n",
    "lon = bbox[0]\n",
    "next_lon = bbox[2]\n",
    "lat = bbox[3]\n",
    "next_lat = bbox[1]\n",
    "from shapely.geometry import Polygon\n",
    "poly = Polygon([(lon,next_lat),(lon,lat),(next_lon,lat),(next_lon,next_lat)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped = regrowth.rio.clip([poly],crs='EPSG:3978',drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped.rio.to_raster('clipped_raster.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(clipped,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes[0].bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.utils import clipNFIS\n",
    "\n",
    "regrowth = rioxarray.open_rasterio(f'/Users/gclyne/Downloads/CA_forest_harvest_years2recovery/CA_forest_harvest_years2recovery.tif',decode_coords='all',lock=False,chunks=True)\n",
    "clipped = clipNFIS(regrowth,boxes[0].bounds[1],boxes[0].bounds[0],boxes[0].bounds[3],boxes[0].bounds[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30], dtype=int8),\n",
       " array([17819004,      452,      331,      250,       93,       54,\n",
       "              58,       51,       43,       18,       19,       18,\n",
       "              15,        6,       13,        8,        8,       13,\n",
       "              10,       11,        4,        8,        4,        3,\n",
       "               3,        3,        5,        2,        3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(clipped,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert numpy unqiue counts to dataframe\n",
    "def convertUniquesToDF(uniq):\n",
    "    df = pd.DataFrame(uniq[1],index=uniq[0])\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['value','count']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "wgs84 = pyproj.CRS('EPSG:4326')\n",
    "utm = pyproj.CRS('EPSG:3978')\n",
    "\n",
    "\n",
    "out_df = pd.DataFrame()\n",
    "for i in boxes:\n",
    "    clipped = clipNFIS(regrowth,i.bounds[1],i.bounds[0],i.bounds[3],i.bounds[2])\n",
    "    print(i.bounds)\n",
    "    project = pyproj.Transformer.from_crs(wgs84, utm, always_xy=True).transform\n",
    "    transformed_box = transform(project, i)\n",
    "    bbox = transformed_box.bounds\n",
    "    c = clipped.sel(x=slice(bbox[0],bbox[2]),y=slice(bbox[3],bbox[1]))\n",
    "    uniq = np.unique(c,return_counts=True)\n",
    "    df = convertUniquesToDF(uniq)\n",
    "    df['lat'] = i.bounds[1]\n",
    "    df['lon'] = i.bounds[0]\n",
    "    #append two dataframes\n",
    "    def append_df(df1, df2):\n",
    "        return pd.concat([df1,df2], ignore_index=True)\n",
    "    out_df = append_df(df,out_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 27], dtype=uint8), array([6153236,     228,     150,     131,      47,      26,      31,\n",
      "            28,      26,      12,       9,      10,       9,       4,\n",
      "             4,       1,       2,       5,       1,       6,       4,\n",
      "             2,       1,       2,       1,       1,       1]))\n"
     ]
    }
   ],
   "source": [
    "import rioxarray \n",
    "import numpy as np\n",
    "regrowth_4326 = rioxarray.open_rasterio(f'/Users/gclyne/thesis/output_raster.tif',decode_coords='all',lock=False,chunks=True)\n",
    "\n",
    "for i in boxes:\n",
    "    out = regrowth_4326.sel(x=slice(i.bounds[0],i.bounds[2]),y=slice(i.bounds[3],i.bounds[1]))\n",
    "    print(np.unique(out,return_counts=True))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.rio.to_raster('out_raster.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>cOther</th>\n",
       "      <th>cCwd</th>\n",
       "      <th>cVeg</th>\n",
       "      <th>cSoilAbove1m</th>\n",
       "      <th>cLitter</th>\n",
       "      <th>cLeaf</th>\n",
       "      <th>cRoot</th>\n",
       "      <th>...</th>\n",
       "      <th>wetlandFrac</th>\n",
       "      <th>ps</th>\n",
       "      <th>pr</th>\n",
       "      <th>tas_DJF</th>\n",
       "      <th>tas_JJA</th>\n",
       "      <th>tas_MAM</th>\n",
       "      <th>tas_SON</th>\n",
       "      <th>grassCropFrac</th>\n",
       "      <th>variant</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850.0</td>\n",
       "      <td>41.937172</td>\n",
       "      <td>-82.50</td>\n",
       "      <td>0.051695</td>\n",
       "      <td>0.075508</td>\n",
       "      <td>0.382676</td>\n",
       "      <td>1.049892</td>\n",
       "      <td>0.028913</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.081992</td>\n",
       "      <td>...</td>\n",
       "      <td>3.118757</td>\n",
       "      <td>98932.187500</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>271.092743</td>\n",
       "      <td>296.431274</td>\n",
       "      <td>282.682648</td>\n",
       "      <td>286.598175</td>\n",
       "      <td>5.525701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.077156e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1850.0</td>\n",
       "      <td>42.879582</td>\n",
       "      <td>-81.25</td>\n",
       "      <td>0.365441</td>\n",
       "      <td>0.924869</td>\n",
       "      <td>3.454496</td>\n",
       "      <td>7.368393</td>\n",
       "      <td>0.224013</td>\n",
       "      <td>0.039276</td>\n",
       "      <td>0.747683</td>\n",
       "      <td>...</td>\n",
       "      <td>5.387547</td>\n",
       "      <td>98765.304688</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>269.867340</td>\n",
       "      <td>295.002899</td>\n",
       "      <td>281.763916</td>\n",
       "      <td>284.794617</td>\n",
       "      <td>29.421182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.061060e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1850.0</td>\n",
       "      <td>42.879582</td>\n",
       "      <td>-80.00</td>\n",
       "      <td>0.248429</td>\n",
       "      <td>0.564599</td>\n",
       "      <td>2.127686</td>\n",
       "      <td>5.366026</td>\n",
       "      <td>0.168735</td>\n",
       "      <td>0.035755</td>\n",
       "      <td>0.465783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218983</td>\n",
       "      <td>98405.867188</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>269.754913</td>\n",
       "      <td>294.573395</td>\n",
       "      <td>281.042877</td>\n",
       "      <td>284.825470</td>\n",
       "      <td>24.893268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.061060e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1850.0</td>\n",
       "      <td>43.821991</td>\n",
       "      <td>-81.25</td>\n",
       "      <td>0.412050</td>\n",
       "      <td>1.170400</td>\n",
       "      <td>3.918015</td>\n",
       "      <td>9.144390</td>\n",
       "      <td>0.254259</td>\n",
       "      <td>0.040559</td>\n",
       "      <td>0.847211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208533</td>\n",
       "      <td>98645.570312</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>268.902679</td>\n",
       "      <td>293.489899</td>\n",
       "      <td>280.233887</td>\n",
       "      <td>283.826385</td>\n",
       "      <td>34.626941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044666e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1850.0</td>\n",
       "      <td>43.821991</td>\n",
       "      <td>-80.00</td>\n",
       "      <td>0.398501</td>\n",
       "      <td>0.877372</td>\n",
       "      <td>2.943997</td>\n",
       "      <td>10.256255</td>\n",
       "      <td>0.273317</td>\n",
       "      <td>0.055604</td>\n",
       "      <td>0.643991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98548.742188</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>268.864777</td>\n",
       "      <td>293.191925</td>\n",
       "      <td>280.160583</td>\n",
       "      <td>283.308472</td>\n",
       "      <td>53.209544</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.044666e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028175</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>83.403145</td>\n",
       "      <td>-73.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244392</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98576.882812</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>242.772339</td>\n",
       "      <td>271.818695</td>\n",
       "      <td>252.222290</td>\n",
       "      <td>258.384857</td>\n",
       "      <td>2.765289</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.567847e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028176</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>83.403145</td>\n",
       "      <td>-72.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146004</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98596.843750</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>242.643265</td>\n",
       "      <td>271.813354</td>\n",
       "      <td>252.203690</td>\n",
       "      <td>258.152008</td>\n",
       "      <td>0.119568</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.567847e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028177</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>83.403145</td>\n",
       "      <td>-71.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98673.312500</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>242.460007</td>\n",
       "      <td>271.718292</td>\n",
       "      <td>252.090530</td>\n",
       "      <td>257.986755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.567847e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028178</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>83.403145</td>\n",
       "      <td>-70.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.031897</td>\n",
       "      <td>0.043866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98804.664062</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>242.284775</td>\n",
       "      <td>271.662750</td>\n",
       "      <td>252.004227</td>\n",
       "      <td>257.858551</td>\n",
       "      <td>18.550827</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.567847e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028179</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>83.403145</td>\n",
       "      <td>-68.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.616646</td>\n",
       "      <td>0.078493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98983.914062</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>242.130676</td>\n",
       "      <td>271.671295</td>\n",
       "      <td>251.929153</td>\n",
       "      <td>257.828064</td>\n",
       "      <td>32.083008</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.567847e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2028180 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           year        lat    lon    cOther      cCwd      cVeg  cSoilAbove1m  \\\n",
       "0        1850.0  41.937172 -82.50  0.051695  0.075508  0.382676      1.049892   \n",
       "1        1850.0  42.879582 -81.25  0.365441  0.924869  3.454496      7.368393   \n",
       "2        1850.0  42.879582 -80.00  0.248429  0.564599  2.127686      5.366026   \n",
       "3        1850.0  43.821991 -81.25  0.412050  1.170400  3.918015      9.144390   \n",
       "4        1850.0  43.821991 -80.00  0.398501  0.877372  2.943997     10.256255   \n",
       "...         ...        ...    ...       ...       ...       ...           ...   \n",
       "2028175  2014.0  83.403145 -73.75  0.000000  0.000000  0.000000      0.244392   \n",
       "2028176  2014.0  83.403145 -72.50  0.000000  0.000000  0.000000      0.146004   \n",
       "2028177  2014.0  83.403145 -71.25  0.000000  0.000000  0.000000      0.145932   \n",
       "2028178  2014.0  83.403145 -70.00  0.000000  0.000000  0.000000     23.031897   \n",
       "2028179  2014.0  83.403145 -68.75  0.000000  0.000000  0.000000     35.616646   \n",
       "\n",
       "          cLitter     cLeaf     cRoot  ...  wetlandFrac            ps  \\\n",
       "0        0.028913  0.006591  0.081992  ...     3.118757  98932.187500   \n",
       "1        0.224013  0.039276  0.747683  ...     5.387547  98765.304688   \n",
       "2        0.168735  0.035755  0.465783  ...     0.218983  98405.867188   \n",
       "3        0.254259  0.040559  0.847211  ...     0.208533  98645.570312   \n",
       "4        0.273317  0.055604  0.643991  ...     0.000000  98548.742188   \n",
       "...           ...       ...       ...  ...          ...           ...   \n",
       "2028175  0.005502  0.000000  0.000000  ...     0.000000  98576.882812   \n",
       "2028176  0.000307  0.000000  0.000000  ...     0.000000  98596.843750   \n",
       "2028177  0.000000  0.000000  0.000000  ...     0.000000  98673.312500   \n",
       "2028178  0.043866  0.000000  0.000000  ...     0.000000  98804.664062   \n",
       "2028179  0.078493  0.000000  0.000000  ...     0.000000  98983.914062   \n",
       "\n",
       "               pr     tas_DJF     tas_JJA     tas_MAM     tas_SON  \\\n",
       "0        0.000028  271.092743  296.431274  282.682648  286.598175   \n",
       "1        0.000028  269.867340  295.002899  281.763916  284.794617   \n",
       "2        0.000030  269.754913  294.573395  281.042877  284.825470   \n",
       "3        0.000026  268.902679  293.489899  280.233887  283.826385   \n",
       "4        0.000027  268.864777  293.191925  280.160583  283.308472   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "2028175  0.000007  242.772339  271.818695  252.222290  258.384857   \n",
       "2028176  0.000007  242.643265  271.813354  252.203690  258.152008   \n",
       "2028177  0.000007  242.460007  271.718292  252.090530  257.986755   \n",
       "2028178  0.000007  242.284775  271.662750  252.004227  257.858551   \n",
       "2028179  0.000007  242.130676  271.671295  251.929153  257.828064   \n",
       "\n",
       "         grassCropFrac  variant          area  \n",
       "0             5.525701      1.0  1.077156e+10  \n",
       "1            29.421182      1.0  1.061060e+10  \n",
       "2            24.893268      1.0  1.061060e+10  \n",
       "3            34.626941      1.0  1.044666e+10  \n",
       "4            53.209544      1.0  1.044666e+10  \n",
       "...                ...      ...           ...  \n",
       "2028175       2.765289      7.0  1.567847e+09  \n",
       "2028176       0.119568      7.0  1.567847e+09  \n",
       "2028177       0.000000      7.0  1.567847e+09  \n",
       "2028178      18.550827      7.0  1.567847e+09  \n",
       "2028179      32.083008      7.0  1.567847e+09  \n",
       "\n",
       "[2028180 rows x 34 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/cesm_data_variant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985\n",
      "(-65.0, 57.015705, -63.75, 57.95811462402344)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/dask/array/core.py:1712: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/dask/array/core.py:1712: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/dask/array/core.py:1712: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/var/folders/1g/_wddvqdx1zn1sqjjw3s9m2940000gt/T/ipykernel_18440/237227457.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  forest_df = forest_df.append({'lat':lat,'lon':lon,'year':year,'percentage_growth':percentage_growth,'tree_cover':tree_cover,'percent_harvested':percent_harvested},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-65.0, 57.958115, -63.75, 58.9005241394043)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/dask/array/core.py:1712: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/dask/array/core.py:1712: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/Users/gclyne/thesis/env/lib/python3.9/site-packages/dask/array/core.py:1712: FutureWarning: The `numpy.size` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/var/folders/1g/_wddvqdx1zn1sqjjw3s9m2940000gt/T/ipykernel_18440/237227457.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  forest_df = forest_df.append({'lat':lat,'lon':lon,'year':year,'percentage_growth':percentage_growth,'tree_cover':tree_cover,'percent_harvested':percent_harvested},ignore_index=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gclyne/thesis/new_prepocessing.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gclyne/thesis/new_prepocessing.ipynb#X45sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m tree_cover \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcount_nonzero(cur_cell) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msize(cur_cell)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gclyne/thesis/new_prepocessing.ipynb#X45sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m percent_harvested \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcount_nonzero(harvested) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msize(cur_cell)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gclyne/thesis/new_prepocessing.ipynb#X45sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m forest_df \u001b[39m=\u001b[39m forest_df\u001b[39m.\u001b[39;49mappend({\u001b[39m'\u001b[39;49m\u001b[39mlat\u001b[39;49m\u001b[39m'\u001b[39;49m:lat,\u001b[39m'\u001b[39;49m\u001b[39mlon\u001b[39;49m\u001b[39m'\u001b[39;49m:lon,\u001b[39m'\u001b[39;49m\u001b[39myear\u001b[39;49m\u001b[39m'\u001b[39;49m:year,\u001b[39m'\u001b[39;49m\u001b[39mpercentage_growth\u001b[39;49m\u001b[39m'\u001b[39;49m:percentage_growth,\u001b[39m'\u001b[39;49m\u001b[39mtree_cover\u001b[39;49m\u001b[39m'\u001b[39;49m:tree_cover,\u001b[39m'\u001b[39;49m\u001b[39mpercent_harvested\u001b[39;49m\u001b[39m'\u001b[39;49m:percent_harvested},ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/pandas/core/frame.py:9045\u001b[0m, in \u001b[0;36mDataFrame.append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   8942\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   8943\u001b[0m \u001b[39mAppend rows of `other` to the end of caller, returning a new object.\u001b[39;00m\n\u001b[1;32m   8944\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9035\u001b[0m \u001b[39m4  4\u001b[39;00m\n\u001b[1;32m   9036\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   9037\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   9038\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThe frame.append method is deprecated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   9039\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mand will be removed from pandas in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9042\u001b[0m     stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   9043\u001b[0m )\n\u001b[0;32m-> 9045\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_append(other, ignore_index, verify_integrity, sort)\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/pandas/core/frame.py:9059\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   9057\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_index:\n\u001b[1;32m   9058\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only append a dict if ignore_index=True\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 9059\u001b[0m     other \u001b[39m=\u001b[39m Series(other)\n\u001b[1;32m   9060\u001b[0m \u001b[39mif\u001b[39;00m other\u001b[39m.\u001b[39mname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_index:\n\u001b[1;32m   9061\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   9062\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCan only append a Series if ignore_index=True \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   9063\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor if the Series has a name\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   9064\u001b[0m     )\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/pandas/core/series.py:417\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    415\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39m_mgr\n\u001b[1;32m    416\u001b[0m \u001b[39melif\u001b[39;00m is_dict_like(data):\n\u001b[0;32m--> 417\u001b[0m     data, index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_dict(data, index, dtype)\n\u001b[1;32m    418\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/pandas/core/series.py:506\u001b[0m, in \u001b[0;36mSeries._init_dict\u001b[0;34m(self, data, index, dtype)\u001b[0m\n\u001b[1;32m    501\u001b[0m     keys, values \u001b[39m=\u001b[39m (), []\n\u001b[1;32m    503\u001b[0m \u001b[39m# Input is now list-like, so rely on \"standard\" construction:\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \n\u001b[1;32m    505\u001b[0m \u001b[39m# TODO: passing np.float64 to not break anything yet. See GH-17261\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m s \u001b[39m=\u001b[39m create_series_with_explicit_dtype(\n\u001b[1;32m    507\u001b[0m     \u001b[39m# error: Argument \"index\" to \"create_series_with_explicit_dtype\" has\u001b[39;49;00m\n\u001b[1;32m    508\u001b[0m     \u001b[39m# incompatible type \"Tuple[Any, ...]\"; expected \"Union[ExtensionArray,\u001b[39;49;00m\n\u001b[1;32m    509\u001b[0m     \u001b[39m# ndarray, Index, None]\"\u001b[39;49;00m\n\u001b[1;32m    510\u001b[0m     values,\n\u001b[1;32m    511\u001b[0m     index\u001b[39m=\u001b[39;49mkeys,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    512\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    513\u001b[0m     dtype_if_empty\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    514\u001b[0m )\n\u001b[1;32m    516\u001b[0m \u001b[39m# Now we just make sure the order is respected, if any\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mand\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/pandas/core/construction.py:859\u001b[0m, in \u001b[0;36mcreate_series_with_explicit_dtype\u001b[0;34m(data, index, dtype, name, copy, fastpath, dtype_if_empty)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[39mif\u001b[39;00m is_empty_data(data) \u001b[39mand\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     dtype \u001b[39m=\u001b[39m dtype_if_empty\n\u001b[0;32m--> 859\u001b[0m \u001b[39mreturn\u001b[39;00m Series(\n\u001b[1;32m    860\u001b[0m     data\u001b[39m=\u001b[39;49mdata, index\u001b[39m=\u001b[39;49mindex, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, copy\u001b[39m=\u001b[39;49mcopy, fastpath\u001b[39m=\u001b[39;49mfastpath\n\u001b[1;32m    861\u001b[0m )\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/pandas/core/series.py:451\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    449\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    450\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    453\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    454\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/pandas/core/construction.py:596\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    594\u001b[0m     subarr \u001b[39m=\u001b[39m _try_cast(data, dtype, copy, raise_cast_failure)\n\u001b[1;32m    595\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     subarr \u001b[39m=\u001b[39m maybe_convert_platform(data)\n\u001b[1;32m    597\u001b[0m     \u001b[39mif\u001b[39;00m subarr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m    598\u001b[0m         subarr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, subarr)\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:122\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    119\u001b[0m arr: ArrayLike\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mrange\u001b[39m)):\n\u001b[0;32m--> 122\u001b[0m     arr \u001b[39m=\u001b[39m construct_1d_object_array_from_listlike(values)\n\u001b[1;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39m# The caller is responsible for ensuring that we have np.ndarray\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[39m#  or ExtensionArray here.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     arr \u001b[39m=\u001b[39m values\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1983\u001b[0m, in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1980\u001b[0m \u001b[39m# numpy will try to interpret nested lists as further dimensions, hence\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m \u001b[39m# making a 1D array that contains list-likes is a bit tricky:\u001b[39;00m\n\u001b[1;32m   1982\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mlen\u001b[39m(values), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1983\u001b[0m result[:] \u001b[39m=\u001b[39m values\n\u001b[1;32m   1984\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/dask/array/core.py:1700\u001b[0m, in \u001b[0;36mArray.__array__\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1700\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute()\n\u001b[1;32m   1701\u001b[0m     \u001b[39mif\u001b[39;00m dtype \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtype:\n\u001b[1;32m   1702\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mastype(dtype)\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/dask/base.py:315\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    292\u001b[0m     \u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[1;32m    294\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39;49m, traverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    316\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/dask/base.py:600\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[1;32m    598\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 600\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    601\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[1;32m     90\u001b[0m     pool\u001b[39m.\u001b[39;49msubmit,\n\u001b[1;32m     91\u001b[0m     pool\u001b[39m.\u001b[39;49m_max_workers,\n\u001b[1;32m     92\u001b[0m     dsk,\n\u001b[1;32m     93\u001b[0m     keys,\n\u001b[1;32m     94\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[1;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39;49m_thread_get_id,\n\u001b[1;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39;49mpack_exception,\n\u001b[1;32m     97\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/dask/local.py:500\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[39mwhile\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mwaiting\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mready\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mrunning\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    499\u001b[0m     fire_tasks(chunksize)\n\u001b[0;32m--> 500\u001b[0m     \u001b[39mfor\u001b[39;00m key, res_info, failed \u001b[39min\u001b[39;00m queue_get(queue)\u001b[39m.\u001b[39mresult():\n\u001b[1;32m    501\u001b[0m         \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m    502\u001b[0m             exc, tb \u001b[39m=\u001b[39m loads(res_info)\n",
      "File \u001b[0;32m~/thesis/env/lib/python3.9/site-packages/dask/local.py:137\u001b[0m, in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mqueue_get\u001b[39m(q):\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m q\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import rioxarray \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ecozones_coords = pd.read_csv('/Users/gclyne/thesis/data/ecozones_coordinates.csv')\n",
    "ecozone_coords = ecozones_coords[ecozones_coords['zone'].isin(['Boreal Cordillera','Boreal PLain', 'Boreal Shield'])]\n",
    "\n",
    "from preprocessing.utils import getGeometryBoxes\n",
    "boxes = getGeometryBoxes(ecozones_coords)\n",
    "forest_df = pd.DataFrame()\n",
    "for_har = rioxarray.open_rasterio('data/reprojected_4326_CA_Forest_Harvest_1985-2020_test.tif',chunks=True)\n",
    "for year in range(1985,1986):\n",
    "    print(year)\n",
    "    cur_forest = rioxarray.open_rasterio(f'home/gclyne/scratch/reprojected_4326_CA_forest_{year}.tif',chunks=True)\n",
    "    last_year_forest = rioxarray.open_rasterio(f'home/gclyne/scratch/reprojected_4326_CA_forest_{year}.tif',chunks=True)\n",
    "    for box in boxes:\n",
    "        print(box.bounds)\n",
    "        lon = box.bounds[0]\n",
    "        next_lon = box.bounds[2]\n",
    "        lat = box.bounds[1]\n",
    "        next_lat = box.bounds[3]\n",
    "        cur_cell = cur_forest.sel(band=1,x=slice(lon,next_lon),y=slice(next_lat,lat))\n",
    "        last_year_cell = last_year_forest.sel(band=1,x=slice(lon,next_lon),y=slice(next_lat,lat))\n",
    "        for_har_cell = for_har.sel(band=1,x=slice(lon,next_lon),y=slice(next_lat,lat))\n",
    "        cur_cell = np.where(cur_cell.data > 200,1,0)\n",
    "        last_year_cell = np.where(last_year_cell.data > 200,1,0)\n",
    "        for_har_prev_harvest = np.where(for_har_cell.data < year,1,0)\n",
    "        harvested = np.where(for_har_cell.data == year,1,0)\n",
    "        #needs to be previously harvested, and not considered forest in the previous year\n",
    "        new_growth = np.where((cur_cell == 1) & (last_year_cell == 0) & (for_har_prev_harvest == 1),1,0)\n",
    "        total_size = np.size(cur_cell)\n",
    "        percentage_growth = np.count_nonzero(new_growth) / total_size\n",
    "        tree_cover = np.count_nonzero(cur_cell) / total_size\n",
    "        percent_harvested = np.count_nonzero(harvested) / total_size\n",
    "\n",
    "        forest_df = pd.concat([forest_df,{'lat':lat,'lon':lon,'year':year,'percentage_growth':percentage_growth,'tree_cover':tree_cover,'percent_harvested':percent_harvested}],ignore_index=True)\n",
    "        break\n",
    "# forest_df.to_csv('forest_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
